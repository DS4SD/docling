<document>
<subtitle-level-1><location><page_1><loc_16><loc_85><loc_82><loc_86></location>TableFormer: Table Structure Understanding with Transformers.</subtitle-level-1>
<subtitle-level-1><location><page_1><loc_23><loc_80><loc_74><loc_81></location>Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak, Peter Staar</subtitle-level-1>
<paragraph><location><page_1><loc_34><loc_77><loc_35><loc_78></location>{</paragraph>
<subtitle-level-1><location><page_1><loc_24><loc_71><loc_31><loc_73></location>Abstract</subtitle-level-1>
<paragraph><location><page_1><loc_10><loc_68><loc_47><loc_70></location>Tables organize valuable content in a concise and com-</paragraph>
<subtitle-level-1><location><page_1><loc_8><loc_30><loc_21><loc_32></location>1. Introduction</subtitle-level-1>
<paragraph><location><page_1><loc_10><loc_28><loc_27><loc_29></location>The occurrence of tables</paragraph>
<subtitle-level-1><location><page_1><loc_52><loc_71><loc_67><loc_72></location>a. Picture of a table:</subtitle-level-1>
<figure>
<location><page_1><loc_52><loc_62><loc_88><loc_71></location>
</figure>
<table>
<location><page_1><loc_52><loc_62><loc_88><loc_71></location>
</table>
<paragraph><location><page_1><loc_52><loc_59><loc_79><loc_60></location>- b. Red-annotation of bounding boxes,</paragraph>
<paragraph><location><page_1><loc_52><loc_46><loc_80><loc_47></location>- c. Structure predicted by TableFormer:</paragraph>
<figure>
<location><page_1><loc_51><loc_48><loc_88><loc_57></location>
</figure>
<figure>
<location><page_1><loc_52><loc_37><loc_88><loc_45></location>
<caption>Figure 1:</caption>
</figure>
<table>
<location><page_1><loc_52><loc_37><loc_88><loc_45></location>
</table>
<paragraph><location><page_1><loc_52><loc_25><loc_59><loc_26></location>Recently,</paragraph>
<paragraph><location><page_1><loc_52><loc_14><loc_89><loc_16></location>The first problem is called table-location and has been</paragraph>
<paragraph><location><page_2><loc_8><loc_89><loc_47><loc_90></location>considered as a solved problem, given enough ground-truth</paragraph>
<paragraph><location><page_2><loc_10><loc_86><loc_47><loc_87></location>The second problem is called table-structure decompo-</paragraph>
<paragraph><location><page_2><loc_10><loc_70><loc_47><loc_71></location>In this paper, we want to address these weaknesses and</paragraph>
<paragraph><location><page_2><loc_10><loc_51><loc_47><loc_53></location>To meet the design criteria listed above, we developed a</paragraph>
<paragraph><location><page_2><loc_10><loc_43><loc_11><loc_44></location>- •</paragraph>
<paragraph><location><page_2><loc_10><loc_35><loc_11><loc_37></location>- •</paragraph>
<paragraph><location><page_2><loc_10><loc_28><loc_11><loc_29></location>- •</paragraph>
<paragraph><location><page_2><loc_10><loc_22><loc_11><loc_24></location>- •</paragraph>
<paragraph><location><page_2><loc_10><loc_17><loc_33><loc_18></location>The paper is structured as follows.</paragraph>
<paragraph><location><page_2><loc_50><loc_89><loc_89><loc_90></location>its results & performance in Sec. 5. As a conclusion, we de-</paragraph>
<subtitle-level-1><location><page_2><loc_50><loc_83><loc_81><loc_85></location>2. Previous work and State of the Art</subtitle-level-1>
<paragraph><location><page_2><loc_52><loc_81><loc_89><loc_82></location>Identifying the structure of a table has been an outstand-</paragraph>
<paragraph><location><page_2><loc_52><loc_57><loc_64><loc_58></location>Before the rising</paragraph>
<paragraph><location><page_2><loc_52><loc_42><loc_69><loc_43></location>Image-to-Text networks</paragraph>
<paragraph><location><page_3><loc_8><loc_89><loc_41><loc_90></location>tag-decoder which is constrained to the table-tags.</paragraph>
<paragraph><location><page_3><loc_10><loc_88><loc_11><loc_89></location>In</paragraph>
<paragraph><location><page_3><loc_10><loc_64><loc_15><loc_65></location>Graph</paragraph>
<paragraph><location><page_3><loc_10><loc_37><loc_41><loc_38></location>Hybrid Deep Learning-Rule-Based approach</paragraph>
<subtitle-level-1><location><page_3><loc_8><loc_18><loc_17><loc_20></location>3. Datasets</subtitle-level-1>
<paragraph><location><page_3><loc_10><loc_16><loc_47><loc_17></location>We rely on large-scale datasets such as PubTabNet [37],</paragraph>
<figure>
<location><page_3><loc_51><loc_68><loc_90><loc_90></location>
<caption>Figure 2:</caption>
</figure>
<paragraph><location><page_3><loc_50><loc_59><loc_71><loc_60></location>balance in the previous datasets.</paragraph>
<paragraph><location><page_3><loc_52><loc_57><loc_89><loc_58></location>The PubTabNet dataset contains 509k tables delivered as</paragraph>
<paragraph><location><page_3><loc_52><loc_19><loc_89><loc_20></location>Due to the heterogeneity across the dataset formats, it</paragraph>
<paragraph><location><page_4><loc_8><loc_89><loc_47><loc_90></location>amount of such tables, and kept only those ones ranging</paragraph>
<paragraph><location><page_4><loc_10><loc_86><loc_47><loc_87></location>The availability of the bounding boxes for all table cells</paragraph>
<paragraph><location><page_4><loc_10><loc_59><loc_47><loc_60></location>As it is illustrated in Fig. 2, the table distributions from</paragraph>
<paragraph><location><page_4><loc_10><loc_43><loc_47><loc_44></location>Motivated by those observations we aimed at generating</paragraph>
<paragraph><location><page_4><loc_10><loc_19><loc_47><loc_20></location>In this regard, we have prepared four synthetic datasets,</paragraph>
<table>
<location><page_4><loc_51><loc_80><loc_89><loc_91></location>
<caption>Table</caption>
</table>
<caption><location><page_4><loc_50><loc_78><loc_54><loc_79></location>Table</caption>
<paragraph><location><page_4><loc_50><loc_67><loc_89><loc_68></location>one adopts a colorful appearance with high contrast and the</paragraph>
<paragraph><location><page_4><loc_52><loc_61><loc_89><loc_62></location>Tab. 1 summarizes the various attributes of the datasets.</paragraph>
<subtitle-level-1><location><page_4><loc_50><loc_58><loc_73><loc_59></location>4. The TableFormer model</subtitle-level-1>
<paragraph><location><page_4><loc_52><loc_56><loc_89><loc_57></location>Given the image of a table, TableFormer is able to pre-</paragraph>
<subtitle-level-1><location><page_4><loc_50><loc_41><loc_69><loc_42></location>4.1. Model architecture.</subtitle-level-1>
<paragraph><location><page_4><loc_52><loc_39><loc_89><loc_40></location>We now describe in detail the proposed method, which</paragraph>
<paragraph><location><page_4><loc_52><loc_14><loc_71><loc_16></location>CNN Backbone Network.</paragraph>
<figure>
<location><page_5><loc_12><loc_77><loc_85><loc_90></location>
<caption>Figure 3:</caption>
</figure>
<figure>
<location><page_5><loc_9><loc_36><loc_47><loc_67></location>
<caption>Figure 4:</caption>
</figure>
<paragraph><location><page_5><loc_50><loc_67><loc_89><loc_68></location>forming classification, and adding an adaptive pooling layer</paragraph>
<paragraph><location><page_5><loc_52><loc_61><loc_66><loc_62></location>Structure Decoder.</paragraph>
<paragraph><location><page_5><loc_52><loc_46><loc_55><loc_47></location>The</paragraph>
<paragraph><location><page_5><loc_52><loc_30><loc_66><loc_31></location>Cell BBox Decoder.</paragraph>
<paragraph><location><page_5><loc_52><loc_16><loc_73><loc_17></location>The encoding generated by the</paragraph>
<paragraph><location><page_6><loc_8><loc_89><loc_47><loc_90></location>tention encoding is then multiplied to the encoded image to</paragraph>
<paragraph><location><page_6><loc_10><loc_79><loc_18><loc_80></location>The output</paragraph>
<paragraph><location><page_6><loc_10><loc_68><loc_21><loc_69></location>Loss Functions.</paragraph>
<paragraph><location><page_6><loc_10><loc_42><loc_47><loc_43></location>The loss used to train the TableFormer can be defined as</paragraph>
<paragraph><location><page_6><loc_8><loc_32><loc_12><loc_33></location>where</paragraph>
<subtitle-level-1><location><page_6><loc_8><loc_28><loc_28><loc_30></location>5. Experimental Results</subtitle-level-1>
<subtitle-level-1><location><page_6><loc_8><loc_26><loc_29><loc_27></location>5.1. Implementation Details</subtitle-level-1>
<paragraph><location><page_6><loc_10><loc_24><loc_33><loc_25></location>TableFormer uses ResNet-18 as the</paragraph>
<paragraph><location><page_6><loc_8><loc_11><loc_47><loc_13></location><location><page_6><loc_8><loc_11><loc_47><loc_13></location>Although input constraints are used also by other methods, runtime performance and lower memory footprint of Table-</paragraph>
<paragraph><location><page_6><loc_52><loc_84><loc_89><loc_85></location>The Transformer Encoder consists of two 'Transformer</paragraph>
<paragraph><location><page_6><loc_52><loc_56><loc_89><loc_57></location>For training, TableFormer is trained with 3 Adam opti-</paragraph>
<paragraph><location><page_6><loc_52><loc_44><loc_89><loc_45></location>TableFormer is implemented with PyTorch and Torchvi-</paragraph>
<subtitle-level-1><location><page_6><loc_50><loc_26><loc_65><loc_27></location>5.2. Generalization</subtitle-level-1>
<paragraph><location><page_6><loc_52><loc_23><loc_89><loc_24></location>TableFormer is evaluated on three major publicly avail-</paragraph>
<paragraph><location><page_6><loc_52><loc_13><loc_89><loc_14></location>We also share our baseline results on the challenging</paragraph>
<subtitle-level-1><location><page_7><loc_8><loc_89><loc_27><loc_91></location>5.3. Datasets and Metrics</subtitle-level-1>
<paragraph><location><page_7><loc_10><loc_87><loc_47><loc_88></location>The Tree-Edit-Distance-Based Similarity (TEDS) met-</paragraph>
<paragraph><location><page_7><loc_10><loc_76><loc_14><loc_77></location>where</paragraph>
<subtitle-level-1><location><page_7><loc_8><loc_70><loc_28><loc_72></location>5.4. Quantitative Analysis</subtitle-level-1>
<paragraph><location><page_7><loc_10><loc_68><loc_17><loc_69></location>Structure.</paragraph>
<table>
<location><page_7><loc_9><loc_26><loc_46><loc_48></location>
</table>
<paragraph><location><page_7><loc_8><loc_24><loc_13><loc_25></location>Table 2:</paragraph>
<paragraph><location><page_7><loc_8><loc_21><loc_43><loc_22></location>FT: Model was trained on PubTabNet then finetuned.</paragraph>
<paragraph><location><page_7><loc_10><loc_18><loc_20><loc_19></location>Cell Detection.</paragraph>
<paragraph><location><page_7><loc_50><loc_89><loc_53><loc_90></location>our</paragraph>
<table>
<location><page_7><loc_50><loc_62><loc_87><loc_69></location>
<caption>Table 3:</caption>
</table>
<caption><location><page_7><loc_50><loc_59><loc_56><loc_60></location>Table 3:</caption>
<paragraph><location><page_7><loc_52><loc_52><loc_62><loc_54></location>Cell Content.</paragraph>
<table>
<location><page_7><loc_54><loc_19><loc_85><loc_32></location>
<caption>Table 4:</caption>
</table>
<caption><location><page_7><loc_50><loc_16><loc_56><loc_17></location>Table 4:</caption>
<paragraph><location><page_8><loc_9><loc_89><loc_82><loc_90></location>- a. Red - PDF cells, Green - predicted bounding boxes, Blue - post-processed predictions matched to PDF cells</paragraph>
<subtitle-level-1><location><page_8><loc_9><loc_87><loc_46><loc_88></location>Japanese language (previously unseen by TableFormer):</subtitle-level-1>
<subtitle-level-1><location><page_8><loc_50><loc_87><loc_70><loc_88></location>Example table from FinTabNet:</subtitle-level-1>
<figure>
<location><page_8><loc_8><loc_76><loc_49><loc_87></location>
</figure>
<figure>
<location><page_8><loc_50><loc_77><loc_91><loc_88></location>
</figure>
<caption><location><page_8><loc_9><loc_73><loc_63><loc_74></location>b. Structure predicted by TableFormer, with superimposed matched PDF cell text:</caption>
<table>
<location><page_8><loc_9><loc_63><loc_49><loc_72></location>
</table>
<table>
<location><page_8><loc_50><loc_64><loc_90><loc_72></location>
</table>
<caption><location><page_8><loc_62><loc_62><loc_90><loc_63></location>Text is aligned to match original for ease of viewing</caption>
<figure>
<location><page_8><loc_63><loc_44><loc_89><loc_52></location>
<caption>Figure 5:</caption>
</figure>
<figure>
<location><page_8><loc_8><loc_44><loc_35><loc_52></location>
<caption>Figure 6:</caption>
</figure>
<subtitle-level-1><location><page_8><loc_8><loc_37><loc_27><loc_38></location>5.5. Qualitative Analysis</subtitle-level-1>
<paragraph><location><page_8><loc_10><loc_31><loc_19><loc_32></location>We showcase</paragraph>
<figure>
<location><page_8><loc_35><loc_44><loc_61><loc_52></location>
</figure>
<subtitle-level-1><location><page_8><loc_50><loc_37><loc_75><loc_38></location>6. Future Work & Conclusion</subtitle-level-1>
<paragraph><location><page_8><loc_52><loc_34><loc_89><loc_35></location>In this paper, we presented TableFormer an end-to-end</paragraph>
<subtitle-level-1><location><page_8><loc_50><loc_14><loc_60><loc_15></location>References</subtitle-level-1>
<paragraph><location><page_8><loc_51><loc_11><loc_53><loc_12></location>- [1]</paragraph>
<paragraph><location><page_9><loc_9><loc_84><loc_11><loc_85></location>- [2]</paragraph>
<paragraph><location><page_9><loc_9><loc_80><loc_11><loc_81></location>- [3]</paragraph>
<paragraph><location><page_9><loc_9><loc_75><loc_11><loc_76></location>- [4]</paragraph>
<paragraph><location><page_9><loc_9><loc_70><loc_11><loc_71></location>- [5]</paragraph>
<paragraph><location><page_9><loc_9><loc_64><loc_11><loc_65></location>- [6]</paragraph>
<paragraph><location><page_9><loc_9><loc_59><loc_11><loc_60></location>- [7]</paragraph>
<paragraph><location><page_9><loc_9><loc_55><loc_11><loc_56></location>- [8]</paragraph>
<paragraph><location><page_9><loc_9><loc_48><loc_11><loc_49></location>- [9]</paragraph>
<paragraph><location><page_9><loc_8><loc_43><loc_11><loc_44></location>- [10]</paragraph>
<paragraph><location><page_9><loc_8><loc_38><loc_11><loc_39></location>- [11]</paragraph>
<paragraph><location><page_9><loc_8><loc_31><loc_11><loc_32></location>- [12]</paragraph>
<paragraph><location><page_9><loc_8><loc_24><loc_11><loc_25></location>- [13]</paragraph>
<paragraph><location><page_9><loc_8><loc_17><loc_11><loc_18></location>- [14]</paragraph>
<paragraph><location><page_9><loc_8><loc_13><loc_11><loc_14></location>- [15]</paragraph>
<paragraph><location><page_9><loc_11><loc_89><loc_35><loc_90></location>- end object detection with transformers.</paragraph>
<paragraph><location><page_9><loc_50><loc_89><loc_53><loc_90></location>- [16]</paragraph>
<paragraph><location><page_9><loc_50><loc_81><loc_53><loc_82></location>- [17]</paragraph>
<paragraph><location><page_9><loc_50><loc_77><loc_53><loc_78></location>- [18]</paragraph>
<paragraph><location><page_9><loc_50><loc_66><loc_53><loc_67></location>- [19]</paragraph>
<paragraph><location><page_9><loc_50><loc_57><loc_53><loc_58></location>- [20]</paragraph>
<paragraph><location><page_9><loc_50><loc_52><loc_53><loc_53></location>- [21]</paragraph>
<paragraph><location><page_9><loc_50><loc_43><loc_53><loc_44></location>- [22]</paragraph>
<paragraph><location><page_9><loc_50><loc_28><loc_53><loc_29></location>- [23]</paragraph>
<paragraph><location><page_9><loc_50><loc_20><loc_53><loc_21></location>- [24]</paragraph>
<paragraph><location><page_9><loc_50><loc_14><loc_53><loc_15></location>- [25]</paragraph>
<paragraph><location><page_10><loc_8><loc_87><loc_11><loc_88></location>- [26]</paragraph>
<paragraph><location><page_10><loc_8><loc_78><loc_11><loc_79></location>- [27]</paragraph>
<paragraph><location><page_10><loc_8><loc_70><loc_11><loc_71></location>- [28]</paragraph>
<paragraph><location><page_10><loc_8><loc_64><loc_11><loc_65></location>- [29]</paragraph>
<paragraph><location><page_10><loc_8><loc_57><loc_11><loc_58></location>- [30]</paragraph>
<paragraph><location><page_10><loc_8><loc_50><loc_11><loc_51></location>- [31]</paragraph>
<paragraph><location><page_10><loc_8><loc_41><loc_11><loc_42></location>- [32]</paragraph>
<paragraph><location><page_10><loc_8><loc_35><loc_11><loc_36></location>- [33]</paragraph>
<paragraph><location><page_10><loc_8><loc_30><loc_11><loc_30></location>- [34]</paragraph>
<paragraph><location><page_10><loc_8><loc_24><loc_11><loc_25></location>- [35]</paragraph>
<paragraph><location><page_10><loc_8><loc_18><loc_11><loc_19></location>- [36]</paragraph>
<paragraph><location><page_10><loc_8><loc_11><loc_11><loc_12></location>- [37]</paragraph>
<paragraph><location><page_10><loc_11><loc_89><loc_37><loc_90></location>Computer Vision and Pattern Recognition</paragraph>
<paragraph><location><page_10><loc_50><loc_84><loc_53><loc_85></location>- [38]</paragraph>
<paragraph><location><page_10><loc_54><loc_89><loc_63><loc_90></location>- and evaluation.</paragraph>
<subtitle-level-1><location><page_11><loc_22><loc_85><loc_76><loc_86></location>TableFormer: Table Structure Understanding with Transformers</subtitle-level-1>
<subtitle-level-1><location><page_11><loc_8><loc_78><loc_29><loc_80></location>1. Details on the datasets</subtitle-level-1>
<paragraph><location><page_11><loc_50><loc_78><loc_70><loc_79></location>ances in regard to their size,</paragraph>
<subtitle-level-1><location><page_11><loc_8><loc_76><loc_25><loc_77></location>1.1. Data preparation</subtitle-level-1>
<paragraph><location><page_11><loc_10><loc_74><loc_47><loc_75></location>As a first step of our data preparation process, we have</paragraph>
<paragraph><location><page_11><loc_10><loc_49><loc_39><loc_51></location>We have developed a technique that tries</paragraph>
<paragraph><location><page_11><loc_10><loc_19><loc_47><loc_20></location>Figure 7 illustrates the distribution of the tables across</paragraph>
<subtitle-level-1><location><page_11><loc_8><loc_15><loc_25><loc_16></location>1.2. Synthetic datasets</subtitle-level-1>
<paragraph><location><page_11><loc_10><loc_13><loc_47><loc_14></location>Aiming to train and evaluate our models in a broader</paragraph>
<subtitle-level-1><location><page_11><loc_50><loc_20><loc_52><loc_21></location>2.</subtitle-level-1>
<paragraph><location><page_11><loc_52><loc_72><loc_89><loc_73></location>The process of generating a synthetic dataset can be de-</paragraph>
<paragraph><location><page_11><loc_52><loc_69><loc_54><loc_70></location>- 1.</paragraph>
<paragraph><location><page_11><loc_52><loc_58><loc_54><loc_60></location>- 2.</paragraph>
<paragraph><location><page_11><loc_52><loc_42><loc_79><loc_43></location>- 3. Generate content: Based on the dataset</paragraph>
<paragraph><location><page_11><loc_52><loc_36><loc_54><loc_37></location>- 4.</paragraph>
<paragraph><location><page_11><loc_52><loc_29><loc_54><loc_31></location>- 5.</paragraph>
<paragraph><location><page_11><loc_52><loc_16><loc_89><loc_17></location>Although TableFormer can predict the table structure and</paragraph>
<figure>
<location><page_12><loc_9><loc_81><loc_89><loc_91></location>
<caption>Figure 7:</caption>
</figure>
<paragraph><location><page_12><loc_10><loc_72><loc_11><loc_73></location>- •</paragraph>
<paragraph><location><page_12><loc_10><loc_68><loc_11><loc_69></location>- •</paragraph>
<paragraph><location><page_12><loc_10><loc_64><loc_47><loc_65></location>However, it is possible to mitigate those limitations by</paragraph>
<paragraph><location><page_12><loc_10><loc_48><loc_47><loc_50></location>Here is a step-by-step description of the prediction post-</paragraph>
<paragraph><location><page_12><loc_10><loc_45><loc_47><loc_47></location>- 1. Get the minimal grid dimensions - number of rows and</paragraph>
<paragraph><location><page_12><loc_10><loc_41><loc_11><loc_42></location>- 2.</paragraph>
<paragraph><location><page_12><loc_10><loc_35><loc_11><loc_36></location>- 3.</paragraph>
<paragraph><location><page_12><loc_10><loc_32><loc_12><loc_33></location>- 3.a.</paragraph>
<paragraph><location><page_12><loc_10><loc_27><loc_11><loc_28></location>- 4.</paragraph>
<paragraph><location><page_12><loc_8><loc_15><loc_12><loc_16></location>where</paragraph>
<paragraph><location><page_12><loc_10><loc_11><loc_11><loc_13></location>- 5.</paragraph>
<paragraph><location><page_12><loc_50><loc_72><loc_71><loc_73></location>dian cell size for all table cells.</paragraph>
<paragraph><location><page_12><loc_52><loc_66><loc_54><loc_67></location>- 6.</paragraph>
<paragraph><location><page_12><loc_52><loc_63><loc_54><loc_64></location>- 7.</paragraph>
<paragraph><location><page_12><loc_52><loc_49><loc_54><loc_51></location>- 8.</paragraph>
<paragraph><location><page_12><loc_52><loc_40><loc_54><loc_41></location>- 9.</paragraph>
<paragraph><location><page_12><loc_52><loc_27><loc_54><loc_28></location>9a.</paragraph>
<paragraph><location><page_12><loc_52><loc_22><loc_54><loc_23></location>- 9b.</paragraph>
<paragraph><location><page_12><loc_52><loc_19><loc_54><loc_20></location>- 9c.</paragraph>
<paragraph><location><page_12><loc_52><loc_15><loc_89><loc_16></location>- 9d. Intersect the orphan's bounding box with the column</paragraph>
<paragraph><location><page_12><loc_52><loc_11><loc_89><loc_13></location>- 9e. If the table cell under the identified row and column</paragraph>
<paragraph><location><page_13><loc_8><loc_89><loc_15><loc_90></location>phan cell.</paragraph>
<paragraph><location><page_13><loc_10><loc_88><loc_12><loc_89></location>9f.</paragraph>
<paragraph><location><page_13><loc_10><loc_85><loc_47><loc_86></location>Aditional images with examples of TableFormer predic-</paragraph>
<table>
<location><page_13><loc_14><loc_73><loc_39><loc_80></location>
</table>
<table>
<location><page_13><loc_14><loc_63><loc_39><loc_70></location>
</table>
<table>
<location><page_13><loc_14><loc_54><loc_39><loc_61></location>
</table>
<table>
<location><page_13><loc_14><loc_38><loc_41><loc_50></location>
</table>
<caption><location><page_13><loc_10><loc_35><loc_16><loc_37></location>Figure 8:</caption>
<table>
<location><page_13><loc_51><loc_83><loc_91><loc_87></location>
<caption>Figure 9:</caption>
</table>
<caption><location><page_13><loc_50><loc_60><loc_56><loc_61></location>Figure 9:</caption>
<table>
<location><page_13><loc_51><loc_77><loc_91><loc_80></location>
</table>
<table>
<location><page_13><loc_51><loc_71><loc_91><loc_75></location>
</table>
<figure>
<location><page_13><loc_51><loc_63><loc_70><loc_68></location>
</figure>
<table>
<location><page_13><loc_51><loc_63><loc_70><loc_68></location>
</table>
<table>
<location><page_13><loc_55><loc_45><loc_80><loc_51></location>
<caption>Figure 10:</caption>
</table>
<caption><location><page_13><loc_51><loc_13><loc_58><loc_14></location>Figure 10:</caption>
<table>
<location><page_13><loc_55><loc_37><loc_80><loc_43></location>
</table>
<table>
<location><page_13><loc_55><loc_28><loc_80><loc_34></location>
</table>
<figure>
<location><page_13><loc_55><loc_16><loc_85><loc_25></location>
</figure>
<table>
<location><page_13><loc_55><loc_16><loc_85><loc_25></location>
</table>
<table>
<location><page_14><loc_8><loc_57><loc_46><loc_65></location>
</table>
<figure>
<location><page_14><loc_8><loc_56><loc_46><loc_87></location>
</figure>
<caption><location><page_14><loc_8><loc_54><loc_15><loc_55></location>Figure 11:</caption>
<table>
<location><page_14><loc_8><loc_38><loc_51><loc_43></location>
</table>
<table>
<location><page_14><loc_8><loc_32><loc_51><loc_36></location>
</table>
<table>
<location><page_14><loc_8><loc_25><loc_51><loc_30></location>
</table>
<figure>
<location><page_14><loc_8><loc_17><loc_29><loc_23></location>
</figure>
<caption><location><page_14><loc_9><loc_14><loc_16><loc_15></location>Figure 12:</caption>
<table>
<location><page_14><loc_52><loc_73><loc_87><loc_80></location>
</table>
<table>
<location><page_14><loc_52><loc_65><loc_87><loc_71></location>
</table>
<table>
<location><page_14><loc_54><loc_55><loc_86><loc_64></location>
</table>
<figure>
<location><page_14><loc_52><loc_55><loc_87><loc_89></location>
<caption>Figure 13:</caption>
</figure>
<table>
<location><page_14><loc_52><loc_40><loc_85><loc_46></location>
<caption>Figure 14:</caption>
</table>
<caption><location><page_14><loc_56><loc_13><loc_63><loc_14></location>Figure 14:</caption>
<table>
<location><page_14><loc_52><loc_32><loc_85><loc_38></location>
</table>
<table>
<location><page_14><loc_52><loc_25><loc_85><loc_31></location>
</table>
<table>
<location><page_14><loc_52><loc_16><loc_87><loc_23></location>
</table>
<figure>
<location><page_15><loc_9><loc_69><loc_46><loc_83></location>
<caption>Figure 15:</caption>
</figure>
<table>
<location><page_15><loc_9><loc_69><loc_46><loc_83></location>
</table>
<figure>
<location><page_15><loc_9><loc_53><loc_46><loc_67></location>
</figure>
<table>
<location><page_15><loc_9><loc_53><loc_46><loc_67></location>
</table>
<figure>
<location><page_15><loc_9><loc_37><loc_46><loc_51></location>
</figure>
<figure>
<location><page_15><loc_8><loc_20><loc_52><loc_36></location>
</figure>
<table>
<location><page_15><loc_8><loc_20><loc_52><loc_36></location>
</table>
<table>
<location><page_15><loc_53><loc_72><loc_86><loc_85></location>
<caption>Figure 16:</caption>
</table>
<caption><location><page_15><loc_50><loc_16><loc_57><loc_18></location>Figure 16:</caption>
<table>
<location><page_15><loc_53><loc_57><loc_86><loc_69></location>
</table>
<figure>
<location><page_15><loc_53><loc_41><loc_86><loc_54></location>
</figure>
<table>
<location><page_15><loc_53><loc_41><loc_86><loc_54></location>
</table>
<figure>
<location><page_15><loc_58><loc_20><loc_81><loc_38></location>
</figure>
<table>
<location><page_15><loc_58><loc_20><loc_81><loc_38></location>
</table>
<figure>
<location><page_16><loc_11><loc_37><loc_86><loc_68></location>
<caption>Figure 17:</caption>
</figure>
</document>