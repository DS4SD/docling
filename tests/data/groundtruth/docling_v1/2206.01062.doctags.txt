<document>
<subtitle-level-1><location><page_1><loc_18><loc_87><loc_83><loc_89></location>DocLayNet: A Large Human-Annotated Dataset for</subtitle-level-1>
<paragraph><location><page_1><loc_17><loc_82><loc_30><loc_83></location>Birgit Pfitzmann</paragraph>
<paragraph><location><page_1><loc_44><loc_82><loc_56><loc_83></location>Christoph Auer</paragraph>
<paragraph><location><page_1><loc_72><loc_82><loc_82><loc_83></location>Michele Dolfi</paragraph>
<paragraph><location><page_1><loc_30><loc_74><loc_43><loc_76></location>Ahmed S. Nassar</paragraph>
<subtitle-level-1><location><page_1><loc_9><loc_67><loc_18><loc_69></location>ABSTRACT</subtitle-level-1>
<paragraph><location><page_1><loc_9><loc_66><loc_48><loc_67></location>Accurate document layout analysis is a key requirement for high-</paragraph>
<subtitle-level-1><location><page_1><loc_9><loc_29><loc_22><loc_30></location>CCS CONCEPTS</subtitle-level-1>
<paragraph><location><page_1><loc_9><loc_27><loc_9><loc_28></location>â€¢</paragraph>
<paragraph><location><page_1><loc_9><loc_19><loc_48><loc_20></location><location><page_1><loc_9><loc_19><loc_48><loc_20></location>Permission to make digital or hard copies of part or all of this work for personal or https://doi.org/10.1145/3534678.3539043</paragraph>
<paragraph><location><page_1><loc_59><loc_74><loc_68><loc_76></location>Peter Staar</paragraph>
<figure>
<location><page_1><loc_53><loc_34><loc_90><loc_68></location>
<caption>Figure 1:</caption>
</figure>
<subtitle-level-1><location><page_1><loc_52><loc_24><loc_62><loc_25></location>KEYWORDS</subtitle-level-1>
<paragraph><location><page_1><loc_52><loc_22><loc_91><loc_23></location>PDF document conversion, layout segmentation, object-detection,</paragraph>
<subtitle-level-1><location><page_1><loc_52><loc_18><loc_66><loc_19></location>ACMReference Format:</subtitle-level-1>
<paragraph><location><page_1><loc_52><loc_17><loc_91><loc_18></location>Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter</paragraph>
<subtitle-level-1><location><page_2><loc_9><loc_88><loc_10><loc_89></location>1</subtitle-level-1>
<paragraph><location><page_2><loc_9><loc_85><loc_50><loc_86></location>Despite the substantial improvements achieved with machine-learning</paragraph>
<paragraph><location><page_2><loc_10><loc_70><loc_48><loc_71></location>Akeyproblem in the process of document conversion is to under-</paragraph>
<paragraph><location><page_2><loc_10><loc_35><loc_48><loc_36></location>In this paper, we present the DocLayNet dataset. It provides page-</paragraph>
<paragraph><location><page_2><loc_11><loc_25><loc_12><loc_26></location>- (1)</paragraph>
<paragraph><location><page_2><loc_11><loc_21><loc_12><loc_22></location>- (2)</paragraph>
<paragraph><location><page_2><loc_11><loc_18><loc_12><loc_19></location>- (3)</paragraph>
<paragraph><location><page_2><loc_11><loc_14><loc_12><loc_15></location>- (4)</paragraph>
<paragraph><location><page_2><loc_56><loc_88><loc_91><loc_89></location>This enables experimentation with annotation uncertainty</paragraph>
<paragraph><location><page_2><loc_54><loc_85><loc_55><loc_86></location>- (5)</paragraph>
<paragraph><location><page_2><loc_54><loc_78><loc_91><loc_79></location>All aspects outlined above are detailed in Section 3. In Section 4,</paragraph>
<paragraph><location><page_2><loc_54><loc_71><loc_91><loc_72></location>In Section 5, we will present baseline accuracy numbers for a</paragraph>
<subtitle-level-1><location><page_2><loc_52><loc_58><loc_53><loc_59></location>2</subtitle-level-1>
<paragraph><location><page_2><loc_52><loc_55><loc_91><loc_56></location>While early approaches in document-layout analysis used rule-</paragraph>
<paragraph><location><page_2><loc_54><loc_40><loc_91><loc_41></location>Lately, new types of ML models for document-layout analysis</paragraph>
<subtitle-level-1><location><page_2><loc_52><loc_27><loc_53><loc_29></location>3</subtitle-level-1>
<paragraph><location><page_2><loc_52><loc_24><loc_91><loc_25></location>DocLayNet contains 80863 PDF pages. Among these, 7059 carry two</paragraph>
<paragraph><location><page_2><loc_54><loc_13><loc_91><loc_14></location>In addition to open intellectual property constraints for the</paragraph>
<figure>
<location><page_3><loc_14><loc_72><loc_43><loc_88></location>
<caption>Figure 2: Distribution of DocLayNet pages across document</caption>
</figure>
<paragraph><location><page_3><loc_9><loc_63><loc_48><loc_64></location>to a minimum, since they introduce difficulties in annotation (see</paragraph>
<paragraph><location><page_3><loc_10><loc_52><loc_48><loc_53></location>The pages in DocLayNet can be grouped into six distinct cate-</paragraph>
<paragraph><location><page_3><loc_10><loc_34><loc_48><loc_35></location>We did not control the document selection with regard to lan-</paragraph>
<paragraph><location><page_3><loc_10><loc_22><loc_48><loc_23></location>To ensure that future benchmarks in the document-layout analy-</paragraph>
<paragraph><location><page_3><loc_54><loc_88><loc_91><loc_89></location>Table 1 shows the overall frequency and distribution of the labels</paragraph>
<paragraph><location><page_3><loc_54><loc_78><loc_91><loc_79></location>In order to accommodate the different types of models currently</paragraph>
<paragraph><location><page_3><loc_54><loc_64><loc_91><loc_65></location>Despite being cost-intense and far less scalable than automation,</paragraph>
<subtitle-level-1><location><page_3><loc_52><loc_22><loc_53><loc_23></location>4</subtitle-level-1>
<paragraph><location><page_3><loc_52><loc_19><loc_91><loc_20></location>The annotation campaign was carried out in four phases. In phase</paragraph>
<table>
<location><page_4><loc_16><loc_63><loc_84><loc_83></location>
<caption>Figure 3: Corpus Conversion Service annotation user inter-</caption>
</table>
<caption><location><page_4><loc_9><loc_29><loc_48><loc_30></location>Figure 3: Corpus Conversion Service annotation user inter-</caption>
<figure>
<location><page_4><loc_9><loc_32><loc_48><loc_61></location>
<caption>Table 1: DocLayNet dataset overview. Along with the frequency of each class label, we present the relative occurrence (as %</caption>
</figure>
<paragraph><location><page_4><loc_9><loc_19><loc_48><loc_20></location>we distributed the annotation workload and performed continuous</paragraph>
<paragraph><location><page_4><loc_10><loc_13><loc_37><loc_14></location>Phase 1: Data selection and preparation.</paragraph>
<paragraph><location><page_4><loc_52><loc_60><loc_79><loc_61></location>include publication repositories such as arXiv</paragraph>
<paragraph><location><page_4><loc_54><loc_51><loc_91><loc_52></location>Preparation work included uploading and parsing the sourced</paragraph>
<paragraph><location><page_4><loc_54><loc_35><loc_79><loc_36></location>Phase 2: Label selection and guideline.</paragraph>
<paragraph><location><page_5><loc_9><loc_88><loc_48><loc_89></location>the textual content of an element, which goes beyond visual layout</paragraph>
<paragraph><location><page_5><loc_10><loc_85><loc_48><loc_86></location>At first sight, the task of visual document-layout interpretation</paragraph>
<paragraph><location><page_5><loc_10><loc_67><loc_48><loc_68></location>Obviously, this inconsistency in annotations is not desirable for</paragraph>
<paragraph><location><page_5><loc_11><loc_55><loc_12><loc_56></location>- (1)</paragraph>
<paragraph><location><page_5><loc_11><loc_49><loc_12><loc_50></location>- (2)</paragraph>
<paragraph><location><page_5><loc_11><loc_44><loc_12><loc_45></location>- (3)</paragraph>
<paragraph><location><page_5><loc_11><loc_41><loc_12><loc_42></location>- (4)</paragraph>
<paragraph><location><page_5><loc_11><loc_38><loc_12><loc_39></location>- (5)</paragraph>
<paragraph><location><page_5><loc_11><loc_37><loc_12><loc_38></location>- (6)</paragraph>
<paragraph><location><page_5><loc_9><loc_32><loc_48><loc_33></location>The complete annotation guideline is over 100 pages long and a</paragraph>
<paragraph><location><page_5><loc_10><loc_26><loc_22><loc_27></location>Phase 3: Training.</paragraph>
<figure>
<location><page_5><loc_52><loc_42><loc_91><loc_89></location>
<caption>Figure 4: Examples of plausible annotation alternatives for</caption>
</figure>
<paragraph><location><page_5><loc_52><loc_33><loc_91><loc_34></location>were carried out over a timeframe of 12 weeks, after which 8 of the</paragraph>
<paragraph><location><page_5><loc_54><loc_30><loc_75><loc_31></location>Phase 4: Production annotation.</paragraph>
<paragraph><location><page_6><loc_9><loc_88><loc_48><loc_89></location>Table 2: Prediction performance (mAP@0.5-0.95) of object</paragraph>
<table>
<location><page_6><loc_10><loc_56><loc_47><loc_75></location>
</table>
<paragraph><location><page_6><loc_9><loc_52><loc_48><loc_53></location>to avoid this at any cost in order to have clear, unbiased baseline</paragraph>
<subtitle-level-1><location><page_6><loc_9><loc_24><loc_10><loc_26></location>5</subtitle-level-1>
<paragraph><location><page_6><loc_9><loc_22><loc_48><loc_23></location>The primary goal of DocLayNet is to obtain high-quality ML models</paragraph>
<figure>
<location><page_6><loc_53><loc_67><loc_90><loc_89></location>
<caption>Figure 5: Prediction performance (mAP@0.5-0.95) of a Mask</caption>
</figure>
<paragraph><location><page_6><loc_52><loc_50><loc_91><loc_51></location>paper and leave the detailed evaluation of more recent methods</paragraph>
<paragraph><location><page_6><loc_54><loc_48><loc_91><loc_49></location>In this section, we will present several aspects related to the</paragraph>
<subtitle-level-1><location><page_6><loc_52><loc_36><loc_76><loc_37></location>Baselines for Object Detection</subtitle-level-1>
<paragraph><location><page_6><loc_52><loc_34><loc_91><loc_35></location>In Table 2, we present baseline experiments (given in mAP) on Mask</paragraph>
<paragraph><location><page_7><loc_9><loc_88><loc_48><loc_89></location>Table 3: Performance of a Mask R-CNN R50 network in</paragraph>
<table>
<location><page_7><loc_13><loc_63><loc_44><loc_81></location>
</table>
<subtitle-level-1><location><page_7><loc_9><loc_58><loc_21><loc_60></location>Learning Curve</subtitle-level-1>
<paragraph><location><page_7><loc_9><loc_57><loc_48><loc_58></location>One of the fundamental questions related to any dataset is if it is</paragraph>
<subtitle-level-1><location><page_7><loc_9><loc_30><loc_27><loc_31></location>Impact of Class Labels</subtitle-level-1>
<paragraph><location><page_7><loc_9><loc_29><loc_48><loc_30></location>The choice and number of labels can have a significant effect on</paragraph>
<paragraph><location><page_7><loc_52><loc_88><loc_91><loc_89></location>Table 4: Performance of a Mask R-CNN R50 network with</paragraph>
<table>
<location><page_7><loc_58><loc_61><loc_85><loc_81></location>
</table>
<paragraph><location><page_7><loc_52><loc_57><loc_91><loc_58></location>lists in PubLayNet (grouped list-items) versus DocLayNet (separate</paragraph>
<subtitle-level-1><location><page_7><loc_52><loc_45><loc_90><loc_46></location>Impact of Document Split in Train and Test Set</subtitle-level-1>
<paragraph><location><page_7><loc_52><loc_43><loc_91><loc_44></location>Many documents in DocLayNet have a unique styling. In order</paragraph>
<subtitle-level-1><location><page_7><loc_52><loc_22><loc_68><loc_23></location>Dataset Comparison</subtitle-level-1>
<paragraph><location><page_7><loc_52><loc_20><loc_91><loc_21></location>Throughout this paper, we claim that DocLayNet's wider variety of</paragraph>
<paragraph><location><page_8><loc_9><loc_88><loc_48><loc_89></location>Table 5: Prediction Performance (mAP@0.5-0.95) of a Mask</paragraph>
<table>
<location><page_8><loc_12><loc_57><loc_45><loc_78></location>
</table>
<paragraph><location><page_8><loc_9><loc_50><loc_17><loc_51></location>Section-header</paragraph>
<paragraph><location><page_8><loc_10><loc_43><loc_48><loc_44></location>For comparison of DocBank with DocLayNet, we trained only</paragraph>
<subtitle-level-1><location><page_8><loc_9><loc_22><loc_25><loc_23></location>Example Predictions</subtitle-level-1>
<paragraph><location><page_8><loc_9><loc_21><loc_48><loc_22></location>To conclude this section, we illustrate the quality of layout predic-</paragraph>
<subtitle-level-1><location><page_8><loc_52><loc_88><loc_53><loc_89></location>6</subtitle-level-1>
<paragraph><location><page_8><loc_52><loc_86><loc_91><loc_87></location>In this paper, we presented the DocLayNet dataset. It provides the</paragraph>
<paragraph><location><page_8><loc_54><loc_75><loc_91><loc_76></location>From the dataset, we have derived on the one hand reference</paragraph>
<paragraph><location><page_8><loc_54><loc_63><loc_91><loc_64></location>To date, there is still a significant gap between human and ML</paragraph>
<subtitle-level-1><location><page_8><loc_52><loc_56><loc_63><loc_58></location>REFERENCES</subtitle-level-1>
<paragraph><location><page_8><loc_52><loc_55><loc_54><loc_56></location>- [1]</paragraph>
<paragraph><location><page_8><loc_52><loc_52><loc_54><loc_53></location>- [2]</paragraph>
<paragraph><location><page_8><loc_52><loc_48><loc_54><loc_49></location>- [3]</paragraph>
<paragraph><location><page_8><loc_52><loc_45><loc_54><loc_46></location>- [4]</paragraph>
<paragraph><location><page_8><loc_52><loc_41><loc_54><loc_42></location>- [5]</paragraph>
<paragraph><location><page_8><loc_52><loc_37><loc_54><loc_38></location>- [6]</paragraph>
<paragraph><location><page_8><loc_52><loc_34><loc_54><loc_35></location>- [7]</paragraph>
<paragraph><location><page_8><loc_52><loc_29><loc_54><loc_30></location>- [8]</paragraph>
<paragraph><location><page_8><loc_52><loc_26><loc_54><loc_27></location>- [9]</paragraph>
<paragraph><location><page_8><loc_52><loc_22><loc_54><loc_23></location>- [10]</paragraph>
<paragraph><location><page_8><loc_52><loc_20><loc_54><loc_21></location>- [11]</paragraph>
<paragraph><location><page_8><loc_52><loc_17><loc_54><loc_18></location>- [12]</paragraph>
<paragraph><location><page_8><loc_52><loc_14><loc_54><loc_15></location>- [13]</paragraph>
<figure>
<location><page_9><loc_9><loc_44><loc_91><loc_89></location>
<caption>Text</caption>
</figure>
<paragraph><location><page_9><loc_9><loc_40><loc_91><loc_41></location>Figure 6: Example layout predictions on selected pages from the DocLayNet test-set. (A, D) exhibit favourable results on</paragraph>
<paragraph><location><page_9><loc_11><loc_33><loc_48><loc_33></location>Diaconu, Mai Thanh Minh, Marc, albinxavi, fatih, oleg, and wanghao yang. ul-</paragraph>
<paragraph><location><page_9><loc_52><loc_33><loc_54><loc_33></location>- [20]</paragraph>
<paragraph><location><page_9><loc_52><loc_31><loc_54><loc_31></location>- [21]</paragraph>
<paragraph><location><page_9><loc_52><loc_28><loc_54><loc_28></location>- [22]</paragraph>
<paragraph><location><page_9><loc_52><loc_24><loc_54><loc_24></location>- [23]</paragraph>
<paragraph><location><page_9><loc_9><loc_30><loc_11><loc_30></location>- [14]</paragraph>
<paragraph><location><page_9><loc_9><loc_27><loc_11><loc_27></location>- [15]</paragraph>
<paragraph><location><page_9><loc_9><loc_25><loc_11><loc_25></location>- [16]</paragraph>
<paragraph><location><page_9><loc_9><loc_22><loc_11><loc_22></location>- [17]</paragraph>
<paragraph><location><page_9><loc_9><loc_20><loc_11><loc_20></location>- [18]</paragraph>
<paragraph><location><page_9><loc_9><loc_15><loc_11><loc_15></location>- [19]</paragraph>
</document>